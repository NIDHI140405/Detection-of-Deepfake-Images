{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOfjeHjmivNp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TIfGIcUixgL"
      },
      "outputs": [],
      "source": [
        "drive.mount ('\\content\\drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcYlPQcJjpUU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzCAyEJnjpnD"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSQfNaSxjprO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DIvaQcEjpuq"
      },
      "outputs": [],
      "source": [
        "Image_Size= 256\n",
        "Batch_Size = 32\n",
        "Channels=3\n",
        "Epochs=55"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twNdEqCDkwOV"
      },
      "outputs": [],
      "source": [
        "imgdata = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/contentdrive/MyDrive/realvsfakeus\",\n",
        "    shuffle=True,\n",
        "    image_size = (Image_Size,Image_Size),\n",
        "    batch_size=Batch_Size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqQNwKnCkwQ4"
      },
      "outputs": [],
      "source": [
        "class_names = imgdata.class_names\n",
        "class_names  # 0 means fake and 1 means real\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaL-JAFSkwTc"
      },
      "outputs": [],
      "source": [
        "for image_batch, label_batch in imgdata.take(1):\n",
        "    print(image_batch.shape)\n",
        "    print(label_batch.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vJ_rsBIkwW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "for image_batch, label_batch in imgdata.take(1):\n",
        "    plt.imshow(image_batch[0].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[label_batch[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ9DNqrVjp0j"
      },
      "outputs": [],
      "source": [
        "def splitting_dataset_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "\n",
        "    ds_size=len(ds)\n",
        "\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "    train_size=int(train_split * ds_size)\n",
        "    val_size= int(val_split * ds_size)\n",
        "\n",
        "    train_ds= ds.take(train_size)\n",
        "\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAO1PQt8lQSS"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_ds, val_ds, test_ds=splitting_dataset_tf(imgdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvu9-zMIlQi7"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(len(train_ds),len(val_ds),len(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLv4fpPMlQnD"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9KamY1nlQqw"
      },
      "outputs": [],
      "source": [
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(Image_Size,Image_Size),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM5e1np3lQ2O"
      },
      "outputs": [],
      "source": [
        "data_aug = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rqfTE45lfiS"
      },
      "outputs": [],
      "source": [
        "input_shape = (Batch_Size,Image_Size, Image_Size,Channels)\n",
        "n_classes = 3\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_aug,\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    # Reduce the number of subsequent Conv2D and MaxPooling2D layers\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.build(input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djldbn9Wlfk0"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFlTMs3MlfoS"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=275,\n",
        "    batch_size=Batch_Size,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YNuQk6GlqrW"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN8mQQtflqug"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for image_batch, label_batch in imgdata.take(1):\n",
        "\n",
        "    first_image = image_batch[0].numpy().astype('uint8')\n",
        "    first_label = label_batch[0].numpy()\n",
        "\n",
        "    print(\"first image to predict\")\n",
        "    plt.imshow(first_image)\n",
        "    print(\"Actual label : \",class_names[first_label])\n",
        "\n",
        "\n",
        "    batch_pred = model.predict(image_batch)\n",
        "    print(\"Pred label : \",class_names[np.argmax(batch_pred[0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOKyiNdQl3C6"
      },
      "outputs": [],
      "source": [
        "def pred(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diR_xagPl3tG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3, i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class, confidence = pred(model, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"Actual : {actual_class},\\n Predicted:{predicted_class}.\\n Confidence:{confidence}%\")\n",
        "\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_3zr95vl6oB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('model_f_real_pickle_final','wb') as f:\n",
        "  pickle.dump(model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fBBgW18l93i"
      },
      "outputs": [],
      "source": [
        "\n",
        "# to run the pickle(saved model)\n",
        "# import pickle\n",
        "\n",
        "with open('model_f_real_pickle_final','rb') as f:\n",
        "  model_saved = pickle.load(f)\n",
        "\n",
        "#to predict the model\n",
        "#model_saved.predict(\"give input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqMdZAQgmC7Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woiwBq-PmDIO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3, i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class, confidence = pred(model_saved, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"Actual : {actual_class},\\n Predicted:{predicted_class}.\\n Confidence:{confidence}%\")\n",
        "\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwSQWRb0ToK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3dEW7g9TolQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}